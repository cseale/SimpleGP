generations_elite-fitness_number-of-evaluations_time
0_6069.029_512_0.6718108654022217
1_5956.551_1536_1.1516783237457275
2_5956.551_2560_1.9508111476898193
3_5956.551_3584_2.3529603481292725
4_5872.221_4608_2.7430002689361572
5_5864.137_5632_3.06972336769104
6_5864.137_6656_3.454254388809204
7_5864.137_7680_3.7518250942230225
8_5864.137_8704_4.044764757156372
9_5864.137_9728_4.339457273483276
10_5864.137_10752_4.6341233253479
11_5864.137_11776_4.923809051513672
12_5769.58_12800_5.284377574920654
13_5769.571_13824_5.595850944519043
14_5758.886_14848_5.986199140548706
15_5751.042_15872_6.515045166015625
16_5743.957_16896_7.280964612960815
17_5727.772_17920_8.08224868774414
18_5712.646_18944_9.228992700576782
19_5712.646_19968_10.716234922409058
20_5702.069_20992_12.543112993240356
21_5698.536_22016_14.495959997177124
22_5698.536_23040_16.914329051971436
23_5663.458_24064_19.776849031448364
24_5658.535_25088_23.892961978912354
Function found (45nodes ):
	[+[ 3.0784952  80.83850369 71.21660732 81.39125042], *[-2.30563407  1.69734988  0.05949623 -1.37724736], x2, *[-2.30563407  1.69734988  0.05949623 -1.37724736], x8, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], *[-2.30563407  1.69734988  0.05949623 -1.37724736], *[-2.30563407  1.69734988  0.05949623 -1.37724736], x2, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], +[ 1.60067622  0.05499391 -0.47925694  0.60774064], *[-2.30563407  1.69734988  0.05949623 -1.37724736], +[ 1.60067622  0.05499391 -0.47925694  0.60774064], *[-2.30563407  1.69734988  0.05949623 -1.37724736], *[-2.30563407  1.69734988  0.05949623 -1.37724736], x2, x2, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], x8, x8, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], x8, x8, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], x8, x3, x8, x8, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], x8, +[ 3.0784952  80.83850369 71.21660732 81.39125042], *[-2.30563407  1.69734988  0.05949623 -1.37724736], x2, *[-2.30563407  1.69734988  0.05949623 -1.37724736], x8, +[ 1.60067622  0.05499391 -0.47925694  0.60774064], x8, +[ 3.0784952  80.83850369 71.21660732 81.39125042], *[-2.30563407  1.69734988  0.05949623 -1.37724736], x2, x2, x2, x2, x8, x2]
Training
	MSE:5658.535
	Rsquared:0.072
Test:
	MSE:3893.956
	Rsquared:0.091
23.8930823802948
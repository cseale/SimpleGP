generations_elite-fitness_number-of-evaluations_time
0_27831.043_128_0.04561734199523926
1_27831.043_256_0.13042092323303223
2_27795.885_384_0.22259879112243652
3_27725.42_512_0.3360872268676758
4_26847.689_640_0.4574856758117676
5_26847.689_768_0.5844929218292236
6_26847.689_896_0.7309136390686035
7_25503.895_1024_0.9014062881469727
8_25503.895_1152_1.0929920673370361
9_25503.895_1280_1.2906839847564697
10_23876.428_1408_1.6195693016052246
11_23876.428_1536_1.7989885807037354
12_23876.428_1664_1.9736497402191162
13_21937.026_1792_2.182725191116333
14_21937.026_1920_2.4191336631774902
15_21937.026_2048_2.6841659545898438
16_16700.674_2176_3.0848872661590576
17_16700.674_2304_3.374333381652832
18_14840.528_2432_3.678285598754883
19_14568.011_2560_4.016672849655151
20_14568.011_2688_4.476913213729858
21_14263.092_2816_4.844938039779663
22_13274.082_2944_5.207914590835571
23_11535.463_3072_5.723106861114502
24_8302.971_3200_6.118995428085327
25_8302.971_3328_6.5125250816345215
26_8302.971_3456_7.062057018280029
27_8302.971_3584_7.5253167152404785
28_6356.578_3712_8.044757604598999
29_6356.578_3840_8.761401176452637
30_6356.578_3968_9.438472509384155
31_6356.578_4096_10.332719564437866
Function found (51nodes ):
	[-[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, 1.791, 1.791, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, 1.791, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, 1.791, 1.791, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, 1.791, 1.791, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], -[-0.23415337 -0.23413696  1.57921282  0.76743473], x4, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, 1.791, 1.791, 1.791]
Training
	MSE:6356.578
	Rsquared:-0.031
Test:
	MSE:5873.86
	Rsquared:-0.032
10.332845211029053
generations_elite-fitness_number-of-evaluations_time
0_28269.427_64_0.02692890167236328
1_27855.678_128_0.0961296558380127
2_27855.678_192_0.3723270893096924
3_27652.529_256_0.4482243061065674
4_25371.027_320_0.523038387298584
5_25371.027_384_0.5827202796936035
6_25371.027_448_0.6414656639099121
7_25371.027_512_0.7295100688934326
8_19898.702_576_0.8598926067352295
9_18174.942_640_1.0300278663635254
10_17650.972_704_1.2311451435089111
11_14445.302_768_1.4609386920928955
12_14445.302_832_1.740889072418213
13_14445.302_896_2.191859245300293
14_13772.709_960_2.6056952476501465
15_13772.709_1023_3.0795626640319824
16_13772.709_1087_3.7442543506622314
17_13772.709_1150_4.2868781089782715
18_13772.709_1212_4.888193368911743
19_13266.477_1273_5.6499834060668945
20_13266.477_1331_6.2838664054870605
21_10753.091_1392_6.98404335975647
22_10750.117_1450_7.494915246963501
23_10750.117_1510_8.032813310623169
24_9299.836_1572_8.720792055130005
25_8787.675_1635_9.308577060699463
26_8787.675_1698_10.073203325271606
Function found (41nodes ):
	[/[ 0.24196227 -1.91328024 -1.72491783 -0.56228753], *[-0.46947439  0.54256004 -0.46341769 -0.46572975], 2.789, -[-0.23415337 -0.23413696  1.57921282  0.76743473], /[ 0.24196227 -1.91328024 -1.72491783 -0.56228753], x0, *[-0.46947439  0.54256004 -0.46341769 -0.46572975], 4.967, -[-0.23415337 -0.23413696  1.57921282  0.76743473], x8, x8, x8, *[-0.46947439  0.54256004 -0.46341769 -0.46572975], 2.789, -[-0.23415337 -0.23413696  1.57921282  0.76743473], /[ 0.24196227 -1.91328024 -1.72491783 -0.56228753], x0, *[-0.46947439  0.54256004 -0.46341769 -0.46572975], *[-0.46947439  0.54256004 -0.46341769 -0.46572975], 2.789, -[-0.23415337 -0.23413696  1.57921282  0.76743473], /[ 0.24196227 -1.91328024 -1.72491783 -0.56228753], x0, *[-0.46947439  0.54256004 -0.46341769 -0.46572975], 4.967, -[-0.23415337 -0.23413696  1.57921282  0.76743473], *[-0.46947439  0.54256004 -0.46341769 -0.46572975], x6, -[-0.23415337 -0.23413696  1.57921282  0.76743473], *[-0.46947439  0.54256004 -0.46341769 -0.46572975], x8, 1.309, x8, x8, x8, -[-0.23415337 -0.23413696  1.57921282  0.76743473], *[-0.46947439  0.54256004 -0.46341769 -0.46572975], x8, 1.309, x8, x8]
Training
	MSE:8787.675
	Rsquared:-0.425
Test:
	MSE:8815.236
	Rsquared:-0.549
10.073418617248535